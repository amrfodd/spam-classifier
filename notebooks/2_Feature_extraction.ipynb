{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d11a44",
   "metadata": {},
   "source": [
    "# Spam Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79b41d",
   "metadata": {},
   "source": [
    "### 1) Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe9096b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re \n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339ed37",
   "metadata": {},
   "source": [
    "### 2) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a09f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from csv file\n",
    "df = pd.read_csv(r'../Data/cleaned_spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7042797e-6a7a-49c6-a347-089744442db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class      0\n",
       "Message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd73e1f-b402-42b4-a241-f9565a75b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be599b45",
   "metadata": {},
   "source": [
    "### 3) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16dd80b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data and target\n",
    "X = df['Message']\n",
    "y = df['class'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49c26668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training, validation and Test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a64fae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Dependent Variable\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "Ytr = encoder.transform(y_train)\n",
    "Yte = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a0ed4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4135,)\n",
      "Shape of X_test: (1034,)\n",
      "Shape of train_vectors: (4135, 2000)\n",
      "Shape of test_vectors: (1034, 2000)\n"
     ]
    }
   ],
   "source": [
    "# I will use TF-IDF method to extract the text features.\n",
    "\n",
    "# Use TF-IDF\n",
    "\n",
    "tf_vec = TfidfVectorizer(tokenizer=None, stop_words=None, max_df=0.75, max_features=2000, lowercase=False,\n",
    "                         ngram_range=(1,2), use_idf=False, sublinear_tf=True, min_df=5, norm='l2',\n",
    "                         encoding='latin-1')\n",
    "\n",
    "\n",
    "train_features = tf_vec.fit(X_train)\n",
    "train_features = tf_vec.transform(X_train)\n",
    "test_features = tf_vec.transform(X_test)\n",
    "\n",
    "\n",
    "#  save tfidf vectorizer\n",
    "with open('../vectors/vectorizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tf_vec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "print('Shape of X_train:',X_train.shape)\n",
    "print('Shape of X_test:',X_test.shape)\n",
    "print('Shape of train_vectors:',train_features.shape)\n",
    "print('Shape of test_vectors:',test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ce417fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save tfidf vectorizer\n",
    "with open('../vectors/train_vector.pkl', 'wb') as handle:\n",
    "    pickle.dump(train_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "with open('../vectors/test_vector.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cdc7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save Target Varab\n",
    "\n",
    "with open('../vectors/train_label.pkl', 'wb') as handle:\n",
    "    pickle.dump(Ytr, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "with open('../vectors/test_label.pkl', 'wb') as handle:\n",
    "    pickle.dump(Yte, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
